{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# %% [markdown]\n",
        "# Model Comparison Command-Line Tool\n",
        "\n",
        "This Jupyter notebook guides you through building a CLI tool to compare OpenAI **Base**, **Instruct**, and **Fine-tuned** models. You can:\n",
        "\n",
        "- Input a query and select a model type\n",
        "- Call the appropriate OpenAI API\n",
        "- Display the response alongside a brief summary of the chosen model’s characteristics\n",
        "\n",
        "---\n",
        "\n",
        "# %% [markdown]\n",
        "## 1. Setup and Dependencies\n",
        "\n",
        "Install required packages:\n",
        "\n",
        "```bash\n",
        "pip install openai python-dotenv\n",
        "```\n",
        "\n",
        "Create a `.env` file (or `.env.example`) with your OpenAI API key and the fine-tuned model name:\n",
        "\n",
        "```\n",
        "OPENAI_API_KEY=your_api_key_here\n",
        "FINE_TUNED_MODEL=your-fine-tuned-model-id-here\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuned models are specialized versions of base models trained on specific datasets for particular tasks or domains. They excel at specialized use cases like content moderation, domain-specific knowledge, or particular writing styles.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import argparse\n",
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "import requests\n",
        "\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# import torch\n",
        "\n",
        "# Load environment variables\n",
        "dotenv_path = os.path.join(os.getcwd(), \".env.example\")\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "# Configure OpenAI API key\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "hf_api_token = os.getenv(\"HF_API_TOKEN\")\n",
        "hf_model = os.getenv(\"HF_FINE_TUNED_MODEL\")\n",
        "\n",
        "# Mapping of model types\n",
        "MODEL_MAP = {\n",
        "    \"base\": {\"provider\": \"openai\", \"model_id\": \"gpt-4o-mini\"},\n",
        "    \"instruct\": {\"provider\": \"openai\", \"model_id\": \"gpt-4o-mini\"}, \n",
        "    \"fine-tuned\": {\"provider\": \"openai\", \"model_id\": \"gpt-4o-mini\"},  # Using same model for demo\n",
        "    # Note: For real fine-tuned models, you would use your custom model ID\n",
        "    # \"fine-tuned\": {\"provider\": \"openai\", \"model_id\": \"ft:gpt-4o-mini:your-org:your-model:abc123\"},\n",
        "    # or a different provider like Hugging Face\n",
        "    # \"fine-tuned\": {\"provider\": \"huggingface\", \"model_id\": hf_model}\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Characteristics descriptions for each model type\n",
        "def get_model_summary(model_type: str) -> str:\n",
        "    summaries = {\n",
        "        \"base\": (\n",
        "            \"Base models are pretrained on large corpora without extra instruction tuning. \"\n",
        "            \"They are flexible but may require more prompt engineering for specific tasks.\"\n",
        "        ),\n",
        "        \"instruct\": (\n",
        "            \"Instruct models are pretrained and then tuned to follow instructions directly. \"\n",
        "            \"They excel at tasks where you need detailed, instruction-driven outputs.\"\n",
        "        ),\n",
        "        \"fine-tuned\": (\n",
        "            \"Fine-tuned models are specialized versions of base models trained on specific datasets \"\n",
        "            \"for particular tasks or domains. They excel at specialized use cases like content moderation, \"\n",
        "            \"domain-specific knowledge, or particular writing styles.\"\n",
        "        )\n",
        "    }\n",
        "    return summaries.get(model_type, \"No summary available.\")\n",
        "print(get_model_summary(\"fine-tuned\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Call OpenAI for base and instruct\n",
        "def call_openai_model(prompt: str, model_id: str) -> str:\n",
        "    try:\n",
        "        # Use chat completions for modern models like gpt-4o-mini\n",
        "        if \"gpt-4\" in model_id or \"gpt-3.5\" in model_id:\n",
        "            response = openai.chat.completions.create(\n",
        "                model=model_id,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=150,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response.choices[0].message.content.strip()\n",
        "        else:\n",
        "            # Use legacy completions for other models\n",
        "            response = openai.completions.create(\n",
        "                model=model_id,\n",
        "                prompt=prompt,\n",
        "                max_tokens=150,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error calling model {model_id}: {str(e)}\"\n",
        "\n",
        "# Call Hugging Face for fine-tuned\n",
        "def call_hf_model(prompt: str, model_id: str) -> str:\n",
        "    url = f\"https://api-inference.huggingface.co/models/{model_id}\"\n",
        "    headers = {\"Authorization\": f\"Bearer {hf_api_token}\"}\n",
        "    payload = {\"inputs\": prompt, \"options\": {\"use_cache\": False}}\n",
        "    res = requests.post(url, headers=headers, json=payload)\n",
        "    res.raise_for_status()\n",
        "    data = res.json()\n",
        "    # Hugging Face returns a list of generation dicts\n",
        "    if isinstance(data, dict) and data.get(\"error\"):\n",
        "        raise ValueError(data[\"error\"])\n",
        "    first = data[0]\n",
        "    return first.get(\"generated_text\", first.get(\"text\", \"\"))\n",
        "\n",
        "# Main API switcher\n",
        "def call_model(query: str, model_type: str) -> str:\n",
        "    config = MODEL_MAP.get(model_type)\n",
        "    if not config:\n",
        "        raise ValueError(f\"Model type '{model_type}' is not configured.\")\n",
        "    provider = config[\"provider\"]\n",
        "    model_id = config[\"model_id\"]\n",
        "\n",
        "    if provider == \"openai\":\n",
        "        return call_openai_model(query, model_id)\n",
        "    elif provider == \"huggingface\":\n",
        "        return call_hf_model(query, model_id)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown provider '{provider}' for model type '{model_type}'.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== BASE MODEL EXAMPLES ===\n",
            "\n",
            "1. Creative Writing:\n",
            "Once upon a time in a digital world, there existed a vibrant realm known as ByteLand. This was a place where data flowed like rivers, and the landscape was dotted with pixelated mountains and shimmering code forests. The inhabitants of ByteLand were not ordinary beings but friendly digital creatures called Bytes, each representing a different type of data: TextBytes, ImageBytes, AudioBytes, and even VideoBytes.\n",
            "\n",
            "The Bytes lived in harmony, sharing information and collaborating to create wondrous applications that enhanced the lives of users in the real world. They built towering structures made of algorithms and formed lush gardens of interactive websites. The air buzzed with the energy of connections, as every Byte worked tirelessly to ensure that information was accessible and enjoyable.\n",
            "\n",
            "However, peace in\n",
            "\n",
            "2. Technical Explanation:\n",
            "Sure! Quantum computing is a type of computing that uses the principles of quantum mechanics, which is the science that describes how very small particles, like atoms and photons, behave.\n",
            "\n",
            "Here are some key concepts in simple terms:\n",
            "\n",
            "1. **Bits vs. Qubits**: Traditional computers use bits as their smallest unit of information, which can be either a 0 or a 1. Quantum computers use qubits, which can be in a state of 0, 1, or both at the same time due to a property called superposition. This allows quantum computers to process a lot more information simultaneously.\n",
            "\n",
            "2. **Superposition**: Imagine a spinning coin. While it's spinning, it's not just heads or tails; it’s in a\n",
            "\n",
            "3. Problem Solving:\n",
            "Solving a Rubik's Cube can be a fun and challenging puzzle! The most popular method for beginners is the Layer-by-Layer (LBL) method. Here’s a step-by-step guide to help you solve a 3x3 Rubik's Cube:\n",
            "\n",
            "### Step 1: Solve the White Cross\n",
            "1. **Choose the white face** as your starting point.\n",
            "2. **Form a cross** by positioning the white edge pieces so that they match the center colors of the adjacent faces.\n",
            "\n",
            "### Step 2: Solve the White Corners\n",
            "1. Find a white corner piece in the bottom layer.\n",
            "2. Position it below where it needs to go (between the correct edge pieces).\n",
            "3. Use the following algorithm to place it\n",
            "\n",
            "4. Philosophical Question:\n",
            "The meaning of life is a profound and often subjective question that has been explored by philosophers, theologians, scientists, and thinkers throughout history. Different cultures, religions, and individuals may offer various interpretations, including:\n",
            "\n",
            "1. **Religious Perspectives**: Many religions suggest that the meaning of life is to fulfill a divine purpose, serve a higher power, or achieve spiritual enlightenment.\n",
            "\n",
            "2. **Philosophical Views**: Philosophers like existentialists argue that life has no inherent meaning, and it is up to individuals to create their own purpose through choices and actions.\n",
            "\n",
            "3. **Scientific Understanding**: From a biological standpoint, the meaning of life might center around survival, reproduction, and the continuation of the species.\n",
            "\n",
            "4. **Personal Fulfillment\n",
            "\n",
            "5. Data Analysis:\n",
            "As of my last knowledge update in October 2023, several key trends have been shaping the renewable energy landscape. Here are some of the most significant trends:\n",
            "\n",
            "### 1. **Increased Investment**\n",
            "Investment in renewable energy has been on the rise, driven by both government incentives and private sector interest. Many countries are committing to ambitious climate goals, leading to substantial funding for solar, wind, and other renewable technologies.\n",
            "\n",
            "### 2. **Cost Declines**\n",
            "The cost of renewable energy technologies continues to decline. Solar photovoltaic (PV) and wind energy have seen significant reductions in cost over the past decade, making them competitive with or cheaper than fossil fuels in many regions. Advances in technology, economies of scale, and competitive bidding processes have all contributed\n",
            "\n",
            "==================================================\n",
            "=== INSTRUCT MODEL EXAMPLES ===\n",
            "\n",
            "1. Email Writing:\n",
            "Subject: Update on Project Timeline\n",
            "\n",
            "Dear [Client's Name],\n",
            "\n",
            "I hope this message finds you well! I wanted to take a moment to update you on the status of our project. \n",
            "\n",
            "First and foremost, I want to thank you for your patience and understanding as we navigate through some unexpected delays. We’ve encountered a few challenges that have slightly shifted our timeline, and I want to ensure you’re kept in the loop regarding our progress.\n",
            "\n",
            "Rest assured, we are actively working to address these issues and minimize any further delays. Our team is committed to maintaining the quality of work you expect from us, and we are implementing solutions to get us back on track as quickly as possible.\n",
            "\n",
            "I appreciate your understanding and support during this time. If you have any\n",
            "\n",
            "2. Recipe Instructions:\n",
            "Sure! Here’s a classic recipe for chocolate chip cookies, along with step-by-step instructions:\n",
            "\n",
            "### Ingredients:\n",
            "- 2 1/4 cups all-purpose flour\n",
            "- 1/2 teaspoon baking soda\n",
            "- 1 cup unsalted butter, room temperature\n",
            "- 1/2 cup granulated sugar\n",
            "- 1 cup packed light-brown sugar\n",
            "- 1 teaspoon salt\n",
            "- 2 teaspoons pure vanilla extract\n",
            "- 2 large eggs\n",
            "- 2 cups semisweet and/or milk chocolate chips\n",
            "- Optional: 1 cup chopped nuts (e.g., walnuts or pecans)\n",
            "\n",
            "### Instructions:\n",
            "\n",
            "#### Step 1: Preheat the Oven\n",
            "1. Preheat your oven to 350°F (175°C\n",
            "\n",
            "3. Educational Content:\n",
            "Sure! Photosynthesis is like a magic trick that plants do to make their own food. Here’s how it works in three simple steps:\n",
            "\n",
            "1. **Sunlight**: Plants need sunlight, just like we need food. They take in sunlight using special parts of their leaves called chlorophyll, which gives leaves their green color.\n",
            "\n",
            "2. **Water and Carbon Dioxide**: Plants also need water and a gas called carbon dioxide. They absorb water through their roots from the soil, and they take in carbon dioxide from the air through tiny openings in their leaves.\n",
            "\n",
            "3. **Making Food**: With the sunlight, water, and carbon dioxide, plants mix everything together inside their leaves. This process creates a type of sugar that plants use as food\n",
            "\n",
            "4. Business Plan:\n",
            "### Business Plan for \"Brewed Awakening Coffee Shop\"\n",
            "\n",
            "**Executive Summary:**\n",
            "Brewed Awakening Coffee Shop aims to provide a cozy and inviting atmosphere for coffee enthusiasts and casual visitors alike. Our mission is to offer high-quality, ethically sourced coffee and a selection of fresh pastries, while fostering a community space for social interaction, work, and relaxation.\n",
            "\n",
            "**Business Objectives:**\n",
            "- Achieve break-even within the first year of operation.\n",
            "- Build a loyal customer base with a target of 500 daily customers by the end of year two.\n",
            "- Establish partnerships with local businesses and artists to host events and promote community engagement.\n",
            "\n",
            "**Market Analysis:**\n",
            "- **Target Market:** Young professionals, students, and local residents aged 18-45\n",
            "\n",
            "5. Travel Guide:\n",
            "Here's a detailed 3-day travel itinerary for your visit to Paris, France:\n",
            "\n",
            "### Day 1: Iconic Landmarks\n",
            "\n",
            "**Morning:**\n",
            "- **Breakfast at a local café:** Start your day with a classic French breakfast of croissants and café au lait at a café like Café de Flore or Les Deux Magots.\n",
            "- **Visit the Eiffel Tower:** Arrive early to beat the crowds. You can either take the elevator to the summit for stunning views or enjoy the views from the second floor.\n",
            "\n",
            "**Afternoon:**\n",
            "- **Lunch in the Trocadéro area:** Try a nearby bistro, such as Café de l’Homme, with views of the Eiffel Tower.\n",
            "- **Seine River Cruise:** After lunch,\n",
            "\n",
            "==================================================\n",
            "=== FINE-TUNED MODEL EXAMPLES ===\n",
            "\n",
            "1. Content Moderation:\n",
            "It seems like you're referring to content that may be inappropriate or offensive. If you need assistance with moderating or rewriting that content, feel free to share more details, and I'll be happy to help!\n",
            "\n",
            "2. Safety Assessment:\n",
            "Sure! Please provide the message you'd like me to evaluate for safety, and I'll be happy to help.\n",
            "\n",
            "3. Policy Compliance:\n",
            "I can't determine whether a specific piece of content violates community guidelines without seeing the content itself. If you provide the content or describe it, I may be able to help you evaluate it based on general community standards.\n",
            "\n",
            "4. Risk Analysis:\n",
            "Sure, I'd be happy to help with that! However, I need you to provide the specific user message that you would like me to analyze for potential risks. Please share the message, and I'll assess it for any potential issues.\n",
            "\n",
            "5. Content Classification:\n",
            "Sure! Please provide the text you'd like me to classify as appropriate or inappropriate.\n"
          ]
        }
      ],
      "source": [
        "# Five different examples for BASE model\n",
        "print(\"=== BASE MODEL EXAMPLES ===\")\n",
        "print(\"\\n1. Creative Writing:\")\n",
        "print(call_model(\"Once upon a time in a digital world\", \"base\"))\n",
        "\n",
        "print(\"\\n2. Technical Explanation:\")\n",
        "print(call_model(\"Explain quantum computing in simple terms\", \"base\"))\n",
        "\n",
        "print(\"\\n3. Problem Solving:\")\n",
        "print(call_model(\"How to solve a Rubik's cube\", \"base\"))\n",
        "\n",
        "print(\"\\n4. Philosophical Question:\")\n",
        "print(call_model(\"What is the meaning of life\", \"base\"))\n",
        "\n",
        "print(\"\\n5. Data Analysis:\")\n",
        "print(call_model(\"Analyze the trends in renewable energy\", \"base\"))\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Five different examples for INSTRUCT model\n",
        "print(\"=== INSTRUCT MODEL EXAMPLES ===\")\n",
        "print(\"\\n1. Email Writing:\")\n",
        "print(call_model(\"Write a friendly email to a client about project delays.\", \"instruct\"))\n",
        "\n",
        "print(\"\\n2. Recipe Instructions:\")\n",
        "print(call_model(\"Give me step-by-step instructions to make chocolate chip cookies\", \"instruct\"))\n",
        "\n",
        "print(\"\\n3. Educational Content:\")\n",
        "print(call_model(\"Explain the process of photosynthesis for a 10-year-old\", \"instruct\"))\n",
        "\n",
        "print(\"\\n4. Business Plan:\")\n",
        "print(call_model(\"Create a brief business plan for a coffee shop\", \"instruct\"))\n",
        "\n",
        "print(\"\\n5. Travel Guide:\")\n",
        "print(call_model(\"Provide a travel itinerary for 3 days in Paris\", \"instruct\"))\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Five different examples for FINE-TUNED model\n",
        "print(\"=== FINE-TUNED MODEL EXAMPLES ===\")\n",
        "print(\"\\n1. Content Moderation:\")\n",
        "print(call_model(\"This post contains inappropriate language\", \"fine-tuned\"))\n",
        "\n",
        "print(\"\\n2. Safety Assessment:\")\n",
        "print(call_model(\"Is this message safe for children\", \"fine-tuned\"))\n",
        "\n",
        "print(\"\\n3. Policy Compliance:\")\n",
        "print(call_model(\"Does this content violate community guidelines\", \"fine-tuned\"))\n",
        "\n",
        "print(\"\\n4. Risk Analysis:\")\n",
        "print(call_model(\"Analyze potential risks in this user message\", \"fine-tuned\"))\n",
        "\n",
        "print(\"\\n5. Content Classification:\")\n",
        "print(call_model(\"Classify this text as appropriate or inappropriate\", \"fine-tuned\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "MODEL TYPE SUMMARIES\n",
            "============================================================\n",
            "\n",
            "BASE MODEL:\n",
            "--------------------\n",
            "Base models are pretrained on large corpora without extra instruction tuning. They are flexible but may require more prompt engineering for specific tasks.\n",
            "\n",
            "\n",
            "INSTRUCT MODEL:\n",
            "--------------------\n",
            "Instruct models are pretrained and then tuned to follow instructions directly. They excel at tasks where you need detailed, instruction-driven outputs.\n",
            "\n",
            "\n",
            "FINE-TUNED MODEL:\n",
            "--------------------\n",
            "Fine-tuned models are specialized versions of base models trained on specific datasets for particular tasks or domains. They excel at specialized use cases like content moderation, domain-specific knowledge, or particular writing styles.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display model summaries\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL TYPE SUMMARIES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for model_type in [\"base\", \"instruct\", \"fine-tuned\"]:\n",
        "    print(f\"\\n{model_type.upper()} MODEL:\")\n",
        "    print(\"-\" * 20)\n",
        "    print(get_model_summary(model_type))\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
